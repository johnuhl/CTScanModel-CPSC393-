# CTScanModel-CPSC393-
This is Ronan Walsh and John Uhl's CPSC 393 (Machine Learning) final project. This is CNN that takes in CT scans of brains, and was able to classify them at a high accuracy. 

# 

The overarching goal of this project is to create a convolutional neural network that is able to take in images of MRI scans and correctly identify whether if a patient has a tumor and if so what kind. Magnetic Resonance Imaging (MRI) scans use magnetic fields and radio waves to send pulses through the skull in order to gain high resolution images of the brain in multiple slices. Tumors, or abnormal cell growths, can form in the brain and, depending on what part of the brain it presses against, can greatly impact motor function or internal bodily systems. Glioma tumors, one of the categories in this dataset, grow on glial cells in the brain and cause symptoms ranging from mild headaches all the way to seizures and loss of language comprehension. These can be found usually along the central nervous system. Pituitary tumors, which can impact vision and disrupt hormones, grow on the pituitary gland which is located on the bottom of the brain. These tumors will look the same on their own and inherently are no different than eachother in composition, but their location dramatically changes what they do to the body. Accurately classifying tumors is extremely important therefore in understanding what is happening and even more important in being able to solve the issue. Hospitals may not always have access to the highest quality equipment for imaging, or could have staﬀing problems leading to an increased rate of human error. An accurate model would very easily be able to step in and be implemented as a cheaper, wholesale resolution to this problem globally for any hospital. As an additional layer, correctly classifying when a tumor is or is not present is monumental; a patient without a tumor who is falsey identifed as having one may go through rigorous treatment, or a patient with a tumor that is missed may suffer to the extent of death without help. It is extremely important to have an accurate and precise model, that is not just able to recognize the presence of a tumor but pinpoint where it is in order to avoid these problems.

# Methods used in the Modeling Process

Our inital approach was to build a standard convolutional neural network with light data augmentation and some pooling. In order to find the best parameters for the models hidden layer activations, overall loss function, and best optimizer we created seperate identical simple CNN models. We then changed only exactly what we were testing for in each model, and ran them with accuracy metrics being tracked. The models were only ran for 10 epochs, as we were not interested in the growth of the model but only comparing them to eachother. Based on the highest and best overall accuracy over the course of the models, we found that relu activation in the hidden layers, a categorical cross entropy loss function, and adam as the optimizer were the best overall choices. This stays consistent with the type of data we were feeding it and what theoritically would be the best choices. For the actual final model, we first created a CNN with 4 distinct layers outside of any augmentation or pooling. The augmentation that was added included a flip, slight rotation, and slight zoom. It is important to keep in mind that MRI scans are a consistent format, and the location of a tumor is very important, so theoretically it would be unrealistic and unhealthy for the model to do any extreme changes. Zooming in too much may remove the tumor from the image, and make it impossible for the model to succeed in what would be an unfair situation; a real doctor would never only have access to part of the image. The flip would also be considered improper, but we did not notice a decline in the models performance and in fact it helped lower the gap in accuracy between the train and test set. An early stop mechanism was put in place as well, with a patience of 5 in order to minimize loss if it were to increase. At this stage, we had a fairly successful model but wanted add more complexity for the goal of the project. Transfer learning was added to the model in the form of the VGG16 block, set for imagenet and the last layers in the block being set to trainable so it could additionally learn to optimize to our data. In order to be compatible with VGG16, we had to add same padding to our model to keep the output from shrinking and changing; we were originally getting mismatched shapes. At this stage, the model was complete and had been able to implement data augmentation, tranfer learning, downsampling, padding, deep layers, early stopping, and included the most optimal parameters for the dataset at hand.


# Discussion of the Results

This model is extremely successful at classifying tumors and being able to correctly identify when they are present or not. While some of the intial versions were doing well with roughly 80% accuracy on the train and 60% on the testing set, the final version with all included pieces was able to gain a 99.9% training accuracy with 0.01 loss, and 98.1% testing accuracy with 0.1 loss. These results are not only extremely positive as we are over the 95% mark in accuracy, but the minimal loss and minimal difference between training and testing accuracy emphasizes the models ability to not just learn the training set but generalize well enough to maintain its success extremely well on unseen data. As well, we measured precision for this model which tells us how good the model was at correctly identifying positive (tumors) cases. In this case the model again excelled with a 99.9% training and 98.1% testing scores. The model has very minimal difference between the two as well, and at such a high score tells us the model is excellent at correctly classifying cases with tumors; the likelihood of someone with a clear MRI scan being marked as positive for tumors would be extremely low. This is great news for our model as it clears expectations we had set in the beginning for moral reasons, as patients lives could be perilously altered with a wrong diagnosis. The model had exceedindly high scores consistently across different sets when measured, and showed low signs of loss. Overall, this is a highly accurate, precise model that was able to effectively learn its training data and generalize to understand and classify new data at a similarly high rate.

# Final Thoughts

In the process of making this model, we attempted several tertiary pieces of code to enhance our understanding of the model performance. Some of these failed attempts included genuine implementation of GridSearch instead of the manual process we went through, or GradCAM visualizations of the layers to see what portions of the scans the model was looking at to make its decisions. However, as we said it failed. True implementation of Gridsearch in these models is possible, but computationally out of our possibility. Gridsearch is more possible and as we saw during the presentations some other groups were able to apply it to their CNN’s; however we were dealing with a type of dataset that was unlike the examples used in GridSearch (our data was a PrefetchDataset) and it was incompatible with traditional solutions. There was successful implementation with it if we chose to turn our model loss into sparse categorical cross entropy, but, we believe sparse categorical cross entropy is not the optimum loss function and does not match the inherent structure of the data we were
feeding it; in agreeance with that notion the model also performed significantly worse when changed (~80% accuracy). Additionally, while all the metrics point positive, it would be very interesting to see how this performs on a wholly different dataset. It clearly was able to master the nuances of the data we were able to find, and there was a lot of images so it was more than just capabale on this set. The transfer learning module should give the model a very consistent baseline, and with MRI scans being uniformly created the differences dataset to dataset would be minimal. However, as mentioned often, the sensitivity of this model is extremely important and it should have further testing to verify our results before being used in any significant medical capacity.
