{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hk7OVNZolLWk"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow.keras as kb\n",
        "from tensorflow.keras import backend\n",
        "import sklearn.model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaEmLoUSmDGr",
        "outputId": "1514152b-81ae-47f5-a3e1-b6593a13055e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "Downloading brain-tumor-mri-dataset.zip to /content\n",
            " 90% 133M/149M [00:01<00:00, 143MB/s]\n",
            "100% 149M/149M [00:02<00:00, 76.6MB/s]\n"
          ]
        }
      ],
      "source": [
        "# upload kaggle.json file into local runtime\n",
        "\n",
        "# make kaggle directory\n",
        "!mkdir ~/.kaggle\n",
        "\n",
        "# move kaggle.json to hidden kaggle folder\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# change permissions on file\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# download zipped data\n",
        "!kaggle datasets download -d masoudnickparvar/brain-tumor-mri-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "aFKuJzcLnO9r"
      },
      "outputs": [],
      "source": [
        "!unzip -qq brain-tumor-mri-dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cq1P6ezloOdw"
      },
      "outputs": [],
      "source": [
        "train_dir = \"./Training\"\n",
        "test_dir = \"./Testing\"\n",
        "val_dir = \"./Validation\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wV5G5ij1p9GG",
        "outputId": "0f9c98a2-7402-4c1f-eaca-508f7c99a6dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8582 files belonging to 8 classes.\n"
          ]
        }
      ],
      "source": [
        "# setting batch size and image size\n",
        "batch_size = 64\n",
        "image_width = 224\n",
        "image_height = 224\n",
        "\n",
        "# creating train ds\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  train_dir, # file path\n",
        "  seed=123, # seed\n",
        "  image_size= (image_width, image_height), # size of image\n",
        "  batch_size=batch_size,\n",
        "  label_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHuZqH1dqrlI",
        "outputId": "ed231e2a-d4ed-488b-a008-7a1c88e6588a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1705 files belonging to 8 classes.\n"
          ]
        }
      ],
      "source": [
        "# creating test ds\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  test_dir, # file path\n",
        "  seed=123, # seed\n",
        "  image_size= (image_width, image_height), # size of image\n",
        "  batch_size= 16, # changing batch size due to less images in this data\n",
        "  label_mode = 'categorical') # number of images per batch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#finding and checking class names\n",
        "import os\n",
        "class_names = sorted(os.listdir(train_dir))\n",
        "print(class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-M5R9w46QGb_",
        "outputId": "f9860b6f-8b12-43e1-88c2-4ff51dcceb51"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['glioma', 'meningioma', 'notumor', 'pituitary']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyper-Parameter Tuning with Smaller CNN Models"
      ],
      "metadata": {
        "id": "EjRwCIMOOEpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a Simple CNN model for tuning loss function - This block tests for Categorical Cross Entropy\n",
        "\n",
        "# simp_model's are identical to eachother except for the above statement, otherwise model specifications are set to what we theorized would be the best, standard\n",
        "simp_model_1 = models.Sequential()\n",
        "\n",
        "simp_model_1.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
        "simp_model_1.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "simp_model_1.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "simp_model_1.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "simp_model_1.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "simp_model_1.add(layers.MaxPooling2D((2, 2)))\n",
        "simp_model_1.add(layers.Flatten())\n",
        "\n",
        "simp_model_1.add(layers.Dense(4, activation='softmax')) # 4 possible outcomes, softmax\n",
        "\n",
        "metrics = ['accuracy']\n",
        "\n",
        "# Compile the model\n",
        "simp_model_1.compile(loss='categorical_crossentropy',  # cat cross because our output is categorical\n",
        "              optimizer=kb.optimizers.Adam(learning_rate=0.0001), # smaller learning rate\n",
        "              metrics= metrics)\n",
        "\n",
        "history = simp_model_1.fit(\n",
        "    train_ds,\n",
        "    epochs= 10, # 10 epochs to keep runtime low\n",
        "    validation_data= test_ds\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "ZQOFvzXjODln",
        "outputId": "28d9cb17-00d0-4d2f-d466-8d238904f669"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-7a62c08b787b>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m               metrics= metrics)\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m history = simp_model_1.fit(\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# 10 epochs to keep runtime low\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1781\u001b[0m                         ):\n\u001b[1;32m   1782\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1783\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1784\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[0;31m# no_variable_creation function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m         return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1262\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1263\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mflat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;34m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    253\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1480\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     ]\n\u001b[0;32m---> 60\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     61\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a Simple CNN model for tuning loss function - This Block Tests for Alternate Activation Functions in the Hidden Layers (Linear)\n",
        "simp_model_2 = models.Sequential()\n",
        "\n",
        "simp_model_2.add(layers.Conv2D(32, (3, 3), activation='linear', input_shape=(224, 224, 3)))\n",
        "simp_model_2.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "simp_model_2.add(layers.Conv2D(64, (3, 3), activation='linear'))\n",
        "simp_model_2.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "simp_model_2.add(layers.Conv2D(128, (3, 3), activation='linear'))\n",
        "simp_model_2.add(layers.MaxPooling2D((2, 2)))\n",
        "simp_model_2.add(layers.Flatten())\n",
        "\n",
        "simp_model_2.add(layers.Dense(4, activation='softmax'))\n",
        "\n",
        "metrics = ['accuracy']\n",
        "\n",
        "# Compile the model\n",
        "simp_model_2.compile(loss='categorical_crossentropy',  # cat cross because our output is categorical\n",
        "              optimizer=kb.optimizers.Adam(learning_rate=0.0001),\n",
        "              metrics= metrics)\n",
        "\n",
        "history = simp_model_2.fit(\n",
        "    train_ds,\n",
        "    epochs= 10,\n",
        "    validation_data= test_ds\n",
        ")"
      ],
      "metadata": {
        "id": "abnfJ9cVj71f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a Simple CNN model for tuning loss function - This Block Tests for Alternate Activation Functions in the Hidden Layers (Relu)\n",
        "simp_model_3 = models.Sequential()\n",
        "\n",
        "simp_model_3.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
        "simp_model_3.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "simp_model_3.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "simp_model_3.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "simp_model_3.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "simp_model_3.add(layers.MaxPooling2D((2, 2)))\n",
        "simp_model_3.add(layers.Flatten())\n",
        "\n",
        "simp_model_3.add(layers.Dense(4, activation='softmax'))\n",
        "\n",
        "metrics = ['accuracy']\n",
        "\n",
        "# Compile the model\n",
        "simp_model_3.compile(loss='categorical_crossentropy',  # cat cross because our output is categorical\n",
        "              optimizer=kb.optimizers.Adam(learning_rate=0.0001),\n",
        "              metrics= metrics)\n",
        "\n",
        "history = simp_model_3.fit(\n",
        "    train_ds,\n",
        "    epochs= 10,\n",
        "    validation_data= test_ds\n",
        ")"
      ],
      "metadata": {
        "id": "RFxUNDc1knfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a Simple CNN model for tuning loss function - This Block Tests for Alternate Activation Functions in the Hidden Layers (tanh)\n",
        "simp_model_4 = models.Sequential()\n",
        "\n",
        "simp_model_4.add(layers.Conv2D(32, (3, 3), activation='tanh', input_shape=(224, 224, 3)))\n",
        "simp_model_4.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "simp_model_4.add(layers.Conv2D(64, (3, 3), activation='tanh'))\n",
        "simp_model_4.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "simp_model_4.add(layers.Conv2D(128, (3, 3), activation='tanh'))\n",
        "simp_model_4.add(layers.MaxPooling2D((2, 2)))\n",
        "simp_model_4.add(layers.Flatten())\n",
        "\n",
        "simp_model_4.add(layers.Dense(4, activation='softmax'))\n",
        "\n",
        "metrics = ['accuracy']\n",
        "\n",
        "# Compile the model\n",
        "simp_model_4.compile(loss='categorical_crossentropy',  # cat cross because our output is categorical\n",
        "              optimizer=kb.optimizers.Adam(learning_rate=0.0001),\n",
        "              metrics= metrics)\n",
        "\n",
        "history = simp_model_4.fit(\n",
        "    train_ds,\n",
        "    epochs= 10,\n",
        "    validation_data= test_ds\n",
        ")"
      ],
      "metadata": {
        "id": "BP7pSghilDLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a Simple CNN model for tuning loss function - This Block Tests for Alternate optimizers (Adam)\n",
        "# based on above results, RELU was chosen to optimize these portions\n",
        "simp_model_5 = models.Sequential()\n",
        "\n",
        "simp_model_5.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
        "simp_model_5.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "simp_model_5.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "simp_model_5.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "simp_model_5.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "simp_model_5.add(layers.MaxPooling2D((2, 2)))\n",
        "simp_model_5.add(layers.Flatten())\n",
        "\n",
        "simp_model_5.add(layers.Dense(4, activation='softmax'))\n",
        "\n",
        "metrics = ['accuracy']\n",
        "\n",
        "# Compile the model\n",
        "simp_model_5.compile(loss='categorical_crossentropy',  # cat cross because our output is categorical\n",
        "              optimizer=kb.optimizers.Adam(learning_rate=0.0001),\n",
        "              metrics= metrics)\n",
        "\n",
        "history = simp_model_5.fit(\n",
        "    train_ds,\n",
        "    epochs= 10,\n",
        "    validation_data= test_ds\n",
        ")"
      ],
      "metadata": {
        "id": "0LyL6O5AlhfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a Simple CNN model for tuning loss function - This Block Tests for Alternate optimizers (AdaGrad)\n",
        "# based on above results, RELU was chosen to optimize these portions\n",
        "simp_model_5 = models.Sequential()\n",
        "\n",
        "simp_model_5.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
        "simp_model_5.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "simp_model_5.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "simp_model_5.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "simp_model_5.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "simp_model_5.add(layers.MaxPooling2D((2, 2)))\n",
        "simp_model_5.add(layers.Flatten())\n",
        "\n",
        "simp_model_5.add(layers.Dense(4, activation='softmax'))\n",
        "\n",
        "metrics = ['accuracy']\n",
        "\n",
        "# Compile the model\n",
        "simp_model_5.compile(loss='categorical_crossentropy',  # cat cross because our output is categorical\n",
        "              optimizer=kb.optimizers.Adagrad(learning_rate=0.0001),\n",
        "              metrics= metrics)\n",
        "\n",
        "history = simp_model_5.fit(\n",
        "    train_ds,\n",
        "    epochs= 10,\n",
        "    validation_data= test_ds\n",
        ")"
      ],
      "metadata": {
        "id": "dd3BHlSxmKtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the above results, the loss function will be categorical cross entropy. The hidden layer activations will be relu, and the optimizer will be Adam. These performed overall the best, as discussed in the report."
      ],
      "metadata": {
        "id": "otIY1SZtmPua"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtKwa_nDNWSU"
      },
      "source": [
        "CNN Model Building"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# transfer learning setup\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "\n",
        "transfer_model = VGG16(input_shape=(image_width,image_height,3), include_top=False, weights='imagenet') # imagenet for images\n",
        "\n",
        "# setting all layers to non-trainable so the module stays intact\n",
        "for layer in transfer_model.layers:\n",
        "    layer.trainable = False\n",
        "# set the last vgg block to trainable to keep some optimization to the training data\n",
        "transfer_model.layers[-2].trainable = True\n",
        "transfer_model.layers[-3].trainable = True\n",
        "transfer_model.layers[-4].trainable = True\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7DKZswonVqe",
        "outputId": "727792d8-424b-4032-ca69-01a0092ae311"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XddGLi4modtH",
        "outputId": "a134f952-7ec0-4639-8b70-aa2ebe16c565"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "90/90 [==============================] - 63s 567ms/step - loss: 0.7956 - accuracy: 0.6707 - precision: 0.8471 - val_loss: 0.2476 - val_accuracy: 0.9139 - val_precision: 0.9288\n",
            "Epoch 2/25\n",
            "90/90 [==============================] - 53s 590ms/step - loss: 0.2693 - accuracy: 0.9121 - precision: 0.9235 - val_loss: 0.1510 - val_accuracy: 0.9431 - val_precision: 0.9448\n",
            "Epoch 3/25\n",
            "90/90 [==============================] - 52s 576ms/step - loss: 0.1638 - accuracy: 0.9452 - precision: 0.9507 - val_loss: 0.0622 - val_accuracy: 0.9806 - val_precision: 0.9821\n",
            "Epoch 4/25\n",
            "90/90 [==============================] - 53s 584ms/step - loss: 0.1041 - accuracy: 0.9648 - precision: 0.9671 - val_loss: 0.0533 - val_accuracy: 0.9842 - val_precision: 0.9846\n",
            "Epoch 5/25\n",
            "90/90 [==============================] - 52s 584ms/step - loss: 0.0652 - accuracy: 0.9814 - precision: 0.9824 - val_loss: 0.0418 - val_accuracy: 0.9856 - val_precision: 0.9867\n",
            "Epoch 6/25\n",
            "90/90 [==============================] - 52s 583ms/step - loss: 0.0419 - accuracy: 0.9879 - precision: 0.9882 - val_loss: 0.0153 - val_accuracy: 0.9953 - val_precision: 0.9956\n",
            "Epoch 7/25\n",
            "90/90 [==============================] - 52s 581ms/step - loss: 0.0368 - accuracy: 0.9883 - precision: 0.9889 - val_loss: 0.0121 - val_accuracy: 0.9963 - val_precision: 0.9967\n",
            "Epoch 8/25\n",
            "90/90 [==============================] - 52s 582ms/step - loss: 0.0263 - accuracy: 0.9916 - precision: 0.9918 - val_loss: 0.0280 - val_accuracy: 0.9911 - val_precision: 0.9912\n",
            "Epoch 9/25\n",
            "90/90 [==============================] - 52s 582ms/step - loss: 0.0219 - accuracy: 0.9928 - precision: 0.9935 - val_loss: 0.0113 - val_accuracy: 0.9963 - val_precision: 0.9965\n",
            "Epoch 10/25\n",
            "90/90 [==============================] - 52s 583ms/step - loss: 0.0177 - accuracy: 0.9940 - precision: 0.9942 - val_loss: 0.0104 - val_accuracy: 0.9965 - val_precision: 0.9970\n",
            "Epoch 11/25\n",
            "90/90 [==============================] - 52s 582ms/step - loss: 0.0285 - accuracy: 0.9921 - precision: 0.9928 - val_loss: 0.0143 - val_accuracy: 0.9958 - val_precision: 0.9958\n",
            "Epoch 12/25\n",
            "90/90 [==============================] - 52s 581ms/step - loss: 0.0120 - accuracy: 0.9963 - precision: 0.9965 - val_loss: 0.0094 - val_accuracy: 0.9967 - val_precision: 0.9968\n",
            "Epoch 13/25\n",
            "90/90 [==============================] - 52s 584ms/step - loss: 0.0314 - accuracy: 0.9918 - precision: 0.9919 - val_loss: 0.0040 - val_accuracy: 0.9988 - val_precision: 0.9988\n",
            "Epoch 14/25\n",
            "90/90 [==============================] - 52s 582ms/step - loss: 0.0107 - accuracy: 0.9974 - precision: 0.9977 - val_loss: 0.0046 - val_accuracy: 0.9989 - val_precision: 0.9989\n",
            "Epoch 15/25\n",
            "90/90 [==============================] - 52s 583ms/step - loss: 0.0276 - accuracy: 0.9925 - precision: 0.9932 - val_loss: 0.0055 - val_accuracy: 0.9979 - val_precision: 0.9981\n",
            "Epoch 16/25\n",
            "90/90 [==============================] - 52s 582ms/step - loss: 0.0074 - accuracy: 0.9982 - precision: 0.9982 - val_loss: 8.2492e-04 - val_accuracy: 0.9998 - val_precision: 0.9998\n",
            "Epoch 17/25\n",
            "90/90 [==============================] - 52s 582ms/step - loss: 0.0012 - accuracy: 0.9998 - precision: 0.9998 - val_loss: 5.8344e-04 - val_accuracy: 0.9998 - val_precision: 0.9998\n",
            "Epoch 18/25\n",
            "90/90 [==============================] - 52s 583ms/step - loss: 7.7492e-04 - accuracy: 0.9998 - precision: 0.9998 - val_loss: 4.2289e-04 - val_accuracy: 0.9998 - val_precision: 0.9998\n",
            "Epoch 19/25\n",
            "90/90 [==============================] - 53s 584ms/step - loss: 5.9505e-04 - accuracy: 0.9998 - precision: 0.9998 - val_loss: 3.9776e-04 - val_accuracy: 0.9998 - val_precision: 0.9998\n",
            "Epoch 20/25\n",
            "90/90 [==============================] - 52s 583ms/step - loss: 7.8835e-04 - accuracy: 0.9998 - precision: 0.9998 - val_loss: 3.6913e-04 - val_accuracy: 0.9998 - val_precision: 0.9998\n",
            "Epoch 21/25\n",
            "90/90 [==============================] - 52s 580ms/step - loss: 3.3241e-04 - accuracy: 1.0000 - precision: 1.0000 - val_loss: 1.9673e-04 - val_accuracy: 1.0000 - val_precision: 1.0000\n",
            "Epoch 22/25\n",
            "90/90 [==============================] - 52s 584ms/step - loss: 1.7220e-04 - accuracy: 1.0000 - precision: 1.0000 - val_loss: 2.1849e-04 - val_accuracy: 0.9998 - val_precision: 1.0000\n",
            "Epoch 23/25\n",
            "90/90 [==============================] - 52s 584ms/step - loss: 1.3414e-04 - accuracy: 1.0000 - precision: 1.0000 - val_loss: 1.4112e-04 - val_accuracy: 1.0000 - val_precision: 1.0000\n",
            "Epoch 24/25\n",
            "90/90 [==============================] - 52s 580ms/step - loss: 1.5076e-04 - accuracy: 1.0000 - precision: 1.0000 - val_loss: 7.9223e-05 - val_accuracy: 1.0000 - val_precision: 1.0000\n",
            "Epoch 25/25\n",
            "90/90 [==============================] - 52s 582ms/step - loss: 5.3750e-04 - accuracy: 0.9996 - precision: 0.9996 - val_loss: 6.1067e-04 - val_accuracy: 0.9998 - val_precision: 0.9998\n"
          ]
        }
      ],
      "source": [
        "# Build the CNN model\n",
        "model = models.Sequential()\n",
        "model.add(transfer_model) # load in the transfer learning model\n",
        "model.add(kb.layers.RandomFlip())\n",
        "\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3))) # opening layer\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(kb.layers.RandomRotation(0.1)) # slight rotate\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same')) # relu with padding\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(kb.layers.RandomZoom(0.1)) # slight zoom\n",
        "\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(layers.MaxPooling2D((2, 2), padding ='same'))\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dropout(0.5)) # semi heavy dropout towards the end to improve generalization\n",
        "\n",
        "model.add(layers.Dense(4, activation='softmax')) # softmax to scale values 0-1 for probabalistic outcome predictions\n",
        "\n",
        "metrics = ['accuracy', tf.keras.metrics.Precision()] # metrics list\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy',  # cat cross because our output is categorical\n",
        "              optimizer=kb.optimizers.Adam(learning_rate=0.0001), # adam for best\n",
        "              metrics= metrics) # cat cross entropy, with best optimizer\n",
        "#\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True) # creating an early stop, stops after 5 epochs of validation loss increase\n",
        "#\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs= 25,  # 25 epochs, most likely will early stop\n",
        "    validation_data = train_ds,\n",
        "    callbacks=[early_stop] # early stop mechanism\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_metrics = model.evaluate(train_ds)\n",
        "test_metrics = model.evaluate(test_ds)\n",
        "\n",
        "print(\"Train Acc:\", train_metrics[1])\n",
        "print(\"Test Acc:\", test_metrics[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2bYX9jj5hle",
        "outputId": "0f9bc991-102a-4868-89b9-8801d0e122c8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90/90 [==============================] - 26s 283ms/step - loss: 6.1067e-04 - accuracy: 0.9998 - precision: 0.9998\n",
            "82/82 [==============================] - 8s 97ms/step - loss: 0.1194 - accuracy: 0.9825 - precision: 0.9824\n",
            "Train Acc: 0.9998249411582947\n",
            "Test Acc: 0.9824561476707458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Train Loss:\", train_metrics[0])\n",
        "print(\"Test Loss:\", test_metrics[0])\n",
        "\n",
        "\n",
        "print(\"Train Acc:\", train_metrics[1])\n",
        "print(\"Test Acc:\", test_metrics[1])\n",
        "\n",
        "print(\"Train Precision:\", train_metrics[2])\n",
        "print(\"Test Precision\", test_metrics[2])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ClnwllksqAW",
        "outputId": "6933f726-69f0-4d89-f6d7-5e5e4f61b3b9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0006106662331148982\n",
            "Test Loss: 0.11937808245420456\n",
            "Train Acc: 0.9998249411582947\n",
            "Test Acc: 0.9824561476707458\n",
            "Train Precision: 0.9998249411582947\n",
            "Test Precision 0.9824427366256714\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}